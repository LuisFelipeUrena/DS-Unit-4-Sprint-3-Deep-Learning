{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "nteract": {
      "version": "0.23.3"
    },
    "colab": {
      "name": "LS_DS_431_RNN_and_LSTM_Assignment_v2.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LuisFelipeUrena/DS-Unit-4-Sprint-3-Deep-Learning/blob/master/Assignments/LS_DS_431_RNN_and_LSTM_Assignment_v2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NbqCAUHVhgNC",
        "colab_type": "text"
      },
      "source": [
        "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
        "<br></br>\n",
        "<br></br>\n",
        "\n",
        "## *Data Science Unit 4 Sprint 3 Assignment 1*\n",
        "\n",
        "# Recurrent Neural Networks and Long Short Term Memory (LSTM)\n",
        "\n",
        "![Monkey at a typewriter](https://upload.wikimedia.org/wikipedia/commons/thumb/3/3c/Chimpanzee_seated_at_typewriter.jpg/603px-Chimpanzee_seated_at_typewriter.jpg)\n",
        "\n",
        "It is said that [infinite monkeys typing for an infinite amount of time](https://en.wikipedia.org/wiki/Infinite_monkey_theorem) will eventually type, among other things, the complete works of Wiliam Shakespeare. Let's see if we can get there a bit faster, with the power of Recurrent Neural Networks and LSTM.\n",
        "\n",
        "This text file contains the complete works of Shakespeare: https://www.gutenberg.org/files/100/100-0.txt\n",
        "\n",
        "Use it as training data for an RNN - you can keep it simple and train character level, and that is suggested as an initial approach.\n",
        "\n",
        "Then, use that trained RNN to generate Shakespearean-ish text. Your goal - a function that can take, as an argument, the size of text (e.g. number of characters or lines) to generate, and returns generated text of that size.\n",
        "\n",
        "Note - Shakespeare wrote an awful lot. It's OK, especially initially, to sample/use smaller data and parameters, so you can have a tighter feedback loop when you're trying to get things running. Then, once you've got a proof of concept - start pushing it more!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2020-06-15T18:18:20.442Z",
          "iopub.execute_input": "2020-06-15T18:18:20.453Z",
          "iopub.status.idle": "2020-06-15T18:18:20.513Z",
          "shell.execute_reply": "2020-06-15T18:18:20.523Z"
        },
        "id": "4194iUkkhgNF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import requests\n",
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2020-06-15T18:25:49.778Z",
          "iopub.execute_input": "2020-06-15T18:25:49.781Z",
          "iopub.status.idle": "2020-06-15T18:25:51.467Z",
          "shell.execute_reply": "2020-06-15T18:25:51.469Z"
        },
        "id": "nxoLemV1hgNT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "url = \"https://www.gutenberg.org/files/100/100-0.txt\"\n",
        "\n",
        "r = requests.get(url)\n",
        "r.encoding = r.apparent_encoding\n",
        "data = r.text\n",
        "data = data.split('\\r\\n')\n",
        "toc = [l.strip() for l in data[44:130:2]]\n",
        "# Skip the Table of Contents\n",
        "data = data[135:]\n",
        "\n",
        "# Fixing Titles\n",
        "toc[9] = 'THE LIFE OF KING HENRY V'\n",
        "toc[18] = 'MACBETH'\n",
        "toc[24] = 'OTHELLO, THE MOOR OF VENICE'\n",
        "toc[34] = 'TWELFTH NIGHT: OR, WHAT YOU WILL'\n",
        "\n",
        "locations = {id_:{'title':title, 'start':-99} for id_,title in enumerate(toc)}\n",
        "\n",
        "# Start \n",
        "for e,i in enumerate(data):\n",
        "    for t,title in enumerate(toc):\n",
        "        if title in i:\n",
        "            locations[t].update({'start':e})\n",
        "            \n",
        "\n",
        "df_toc = pd.DataFrame.from_dict(locations, orient='index')\n",
        "df_toc['end'] = df_toc['start'].shift(-1).apply(lambda x: x-1)\n",
        "df_toc.loc[42, 'end'] = len(data)\n",
        "df_toc['end'] = df_toc['end'].astype('int')\n",
        "\n",
        "df_toc['text'] = df_toc.apply(lambda x: '\\r\\n'.join(data[ x['start'] : int(x['end']) ]), axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "execution": {
          "iopub.status.busy": "2020-06-15T18:26:12.630Z",
          "iopub.execute_input": "2020-06-15T18:26:12.637Z",
          "iopub.status.idle": "2020-06-15T18:26:12.643Z",
          "shell.execute_reply": "2020-06-15T18:26:12.647Z"
        },
        "id": "Zd1XrtIJhgNc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "96af2b5e-a073-4b13-f4a3-6da96c8f6884"
      },
      "source": [
        "#Shakespeare Data Parsed by Play\n",
        "df_toc.head()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>start</th>\n",
              "      <th>end</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ALL’S WELL THAT ENDS WELL</td>\n",
              "      <td>2777</td>\n",
              "      <td>7738</td>\n",
              "      <td>ALL’S WELL THAT ENDS WELL\\r\\n\\r\\n\\r\\n\\r\\nConte...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>THE TRAGEDY OF ANTONY AND CLEOPATRA</td>\n",
              "      <td>7739</td>\n",
              "      <td>11840</td>\n",
              "      <td>THE TRAGEDY OF ANTONY AND CLEOPATRA\\r\\n\\r\\nDRA...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>AS YOU LIKE IT</td>\n",
              "      <td>11841</td>\n",
              "      <td>14631</td>\n",
              "      <td>AS YOU LIKE IT\\r\\n\\r\\nDRAMATIS PERSONAE.\\r\\n\\r...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>THE COMEDY OF ERRORS</td>\n",
              "      <td>14632</td>\n",
              "      <td>17832</td>\n",
              "      <td>THE COMEDY OF ERRORS\\r\\n\\r\\n\\r\\n\\r\\nContents\\r...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>THE TRAGEDY OF CORIOLANUS</td>\n",
              "      <td>17833</td>\n",
              "      <td>27806</td>\n",
              "      <td>THE TRAGEDY OF CORIOLANUS\\r\\n\\r\\nDramatis Pers...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                 title  ...                                               text\n",
              "0            ALL’S WELL THAT ENDS WELL  ...  ALL’S WELL THAT ENDS WELL\\r\\n\\r\\n\\r\\n\\r\\nConte...\n",
              "1  THE TRAGEDY OF ANTONY AND CLEOPATRA  ...  THE TRAGEDY OF ANTONY AND CLEOPATRA\\r\\n\\r\\nDRA...\n",
              "2                       AS YOU LIKE IT  ...  AS YOU LIKE IT\\r\\n\\r\\nDRAMATIS PERSONAE.\\r\\n\\r...\n",
              "3                 THE COMEDY OF ERRORS  ...  THE COMEDY OF ERRORS\\r\\n\\r\\n\\r\\n\\r\\nContents\\r...\n",
              "4            THE TRAGEDY OF CORIOLANUS  ...  THE TRAGEDY OF CORIOLANUS\\r\\n\\r\\nDramatis Pers...\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aDv9G9shireb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "074e1c60-1b59-4851-90c8-729d8076faf7"
      },
      "source": [
        "df_toc.shape"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(43, 4)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qjo_SvwNjAoM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.preprocessing import sequence\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Embedding\n",
        "from tensorflow.keras.layers import LSTM\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import numpy as np\n",
        "import random\n",
        "import sys\n",
        "import os"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f19afvm9ktzl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = df_toc['text'].to_list()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QnredndNkb6J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Encode Data as Chars\n",
        "\n",
        "# Gather all text \n",
        "# Why? 1. See all possible characters 2. For training / splitting later\n",
        "text = \" \".join(data)\n",
        "\n",
        "# Unique Characters\n",
        "chars = list(set(text))\n",
        "\n",
        "# Lookup Tables\n",
        "char_int = {c:i for i, c in enumerate(chars)} \n",
        "int_char = {i:c for i, c in enumerate(chars)} "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kC5RUjyqnji4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4772058c-d50b-48b8-a706-202991d74c6a"
      },
      "source": [
        "# Create the sequence data\n",
        "\n",
        "maxlen = 40\n",
        "step = 5\n",
        "\n",
        "encoded = [char_int[c] for c in text]\n",
        "\n",
        "sequences = [] # Each element is 40 chars long\n",
        "next_char = [] # One element for each sequence\n",
        "\n",
        "for i in range(0, len(encoded) - maxlen, step):\n",
        "    \n",
        "    sequences.append(encoded[i : i + maxlen])\n",
        "    next_char.append(encoded[i + maxlen])\n",
        "    \n",
        "print('sequences: ', len(sequences))\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sequences:  1114068\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vBGF6sDsojIk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create x & y\n",
        "\n",
        "x = np.zeros((len(sequences), maxlen, len(chars)), dtype=np.bool)\n",
        "y = np.zeros((len(sequences),len(chars)), dtype=np.bool)\n",
        "\n",
        "for i, sequence in enumerate(sequences):\n",
        "    for t, char in enumerate(sequence):\n",
        "        x[i,t,char] = 1\n",
        "        \n",
        "    y[i, next_char[i]] = 1\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U4OAmfhrpMNY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7a99a67f-f1e2-41d3-a357-93a281097461"
      },
      "source": [
        "x.shape"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1114068, 40, 104)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "laeiTJeQp1wg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential()\n",
        "model.add(LSTM(128, input_shape=(maxlen, len(chars))))\n",
        "model.add(Dense(len(chars), activation='softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KuRFFw2cqw7a",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        },
        "outputId": "124a4b49-c870-455d-caba-8843217fb0b3"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_2 (LSTM)                (None, 128)               119296    \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 104)               13416     \n",
            "=================================================================\n",
            "Total params: 132,712\n",
            "Trainable params: 132,712\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TqrPzdxKsW9r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sample(preds):\n",
        "    # helper function to sample an index from a probability array\n",
        "    preds = np.asarray(preds).astype('float64')\n",
        "    preds = np.log(preds) / 1\n",
        "    exp_preds = np.exp(preds)\n",
        "    preds = exp_preds / np.sum(exp_preds)\n",
        "    probas = np.random.multinomial(1, preds, 1)\n",
        "    return np.argmax(probas)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kwF_87Yrqz2z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.callbacks import LambdaCallback\n",
        "\n",
        "def on_epoch_end(epoch, _):\n",
        "    # Function invoked at end of each epoch. Prints generated text.\n",
        "    \n",
        "    print()\n",
        "    print('----- Generating text after Epoch: %d' % epoch)\n",
        "    \n",
        "    start_index = random.randint(0, len(text) - maxlen - 1)\n",
        "    \n",
        "    generated = ''\n",
        "    \n",
        "    sentence = text[start_index: start_index + maxlen]\n",
        "    generated += sentence\n",
        "    \n",
        "    print('----- Generating with seed: \"' + sentence + '\"')\n",
        "    sys.stdout.write(generated)\n",
        "    \n",
        "    for i in range(400):\n",
        "        x_pred = np.zeros((1, maxlen, len(chars)))\n",
        "        for t, char in enumerate(sentence):\n",
        "            x_pred[0, t, char_int[char]] = 1\n",
        "            \n",
        "        preds = model.predict(x_pred, verbose=0)[0]\n",
        "        next_index = sample(preds)\n",
        "        next_char = int_char[next_index]\n",
        "        \n",
        "        sentence = sentence[1:] + next_char\n",
        "        \n",
        "        sys.stdout.write(next_char)\n",
        "        sys.stdout.flush()\n",
        "    print()\n",
        "\n",
        "\n",
        "print_callback = LambdaCallback(on_epoch_end=on_epoch_end)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DrEPexWHp_GK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "01865d58-6089-49d0-99ea-ceca525bc2b3"
      },
      "source": [
        "model.fit(x, y,\n",
        "          batch_size=32,\n",
        "          epochs=10,\n",
        "          callbacks=[print_callback]\n",
        "          )"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "34815/34815 [==============================] - ETA: 0s - loss: 2.0009\n",
            "----- Generating text after Epoch: 0\n",
            "----- Generating with seed: \"g queens;     And therefore level not to\"\n",
            "g queens;     And therefore level not to so verites. But you fave the guse other clies I times to see sides Fhere plave we trent.   [_Hare 'ing of our foabord proverange.  SACHOLGY. He doffal'd her al! so, dour, [_To Gstiuncy!   LOUCHMANT. It, do this mad and mes she of my sair.  TAMONLA. My bigst in thou shall wells specid's mangers spictus; but I prunce.                    [Exeunt Exeunt the HORY. Kave you, Belible! Hasure chath my ke\n",
            "34815/34815 [==============================] - 150s 4ms/step - loss: 2.0009\n",
            "Epoch 2/10\n",
            "34808/34815 [============================>.] - ETA: 0s - loss: 1.7008\n",
            "----- Generating text after Epoch: 1\n",
            "----- Generating with seed: \" battery once again, I will not leave th\"\n",
            " battery once again, I will not leave this more cractiforgious of their time reard, Ayt this Cellainure,                         894  I’ll gete, boddous Hertiness of a garch entrigh,     His a brows prouchiod cuturay, mets so, my noriguty well;     The shall He had appassed as bard Kint.                  wndent first noble friend Duster of swore harg our house.   ALL. When disshile my heage     Toon shall let thou note this mide as lest\n",
            "34815/34815 [==============================] - 151s 4ms/step - loss: 1.7008\n",
            "Epoch 3/10\n",
            "34808/34815 [============================>.] - ETA: 0s - loss: 1.6082\n",
            "----- Generating text after Epoch: 2\n",
            "----- Generating with seed: \"t I; 'twas Chiron and Demetrius.     The\"\n",
            "t I; 'twas Chiron and Demetrius.     They a mann'd us, Or andainony saches with for them. We helpeeth—thy bast in monesin the need fither,     Bigier, shall yet.  PHILIO, of this.     Exeunt though be agine thy cheepell Druntorred.   POLIUL and Vicecount._]   LORD. Pile, and my lace?  PEERICHAND. Laydy died, good morest, be sey have a deels,     Than'st the comerfoice too, and him,     All a garren comes, when, whod may, pitewer’d of me\n",
            "34815/34815 [==============================] - 150s 4ms/step - loss: 1.6082\n",
            "Epoch 4/10\n",
            "34810/34815 [============================>.] - ETA: 0s - loss: 1.5570\n",
            "----- Generating text after Epoch: 3\n",
            "----- Generating with seed: \", Come not before him.  FLORIZEL. I not \"\n",
            ", Come not before him.  FLORIZEL. I not cheet, but I will dutist out to the countrowles this?   [_1hathioms_._]  AETIAN. Thit, my lord thoo well; I lade and dare, faith baskers. It consid and palace with my comweenies, Now to the honours excreesmes in Athenn,     I cannot with’s here, I will prom him shall not did mont!     And told. The kisl the libs with her That fits tu sare somance shaul sthar, I will see that I do so tall, this hin\n",
            "34815/34815 [==============================] - 153s 4ms/step - loss: 1.5570\n",
            "Epoch 5/10\n",
            "34804/34815 [============================>.] - ETA: 0s - loss: 1.5237\n",
            "----- Generating text after Epoch: 4\n",
            "----- Generating with seed: \"some shade, And fit you to your manhood.\"\n",
            "some shade, And fit you to your manhood. But, bry this woil.                                      ExithOR    ANTONO SSTIRICONES the thrust ROSTRESTROY. Moon thought Grey Calising out;     Anvice; with Turins of my no looct. Here ghat, my lov'd by thy hime That best man to the     Unt The ald warript for you atter.     The reat at the when all to a busines,   “ANd man ladies, vanded my preselus.  great burn honout.  GAUNCE. Ay, this warm\n",
            "34815/34815 [==============================] - 153s 4ms/step - loss: 1.5237\n",
            "Epoch 6/10\n",
            "34813/34815 [============================>.] - ETA: 0s - loss: 1.4994\n",
            "----- Generating text after Epoch: 5\n",
            "----- Generating with seed: \" was not brought me, my lord, there’s th\"\n",
            " was not brought me, my lord, there’s the Kenser raigno. My bond here so     Your hown’s lad, boin may'st think; live wrong! Saker against my appear, the capine's whised Brit it, burn too which king,     Seem truth’s it.  PHILION. The, thou holider to encre     Than your lefong and law ’t, well lend.  MARIA. He end your neckless’d His and slain for it,     Grant still purfute.  FIRST SENATOR. Con, too!  WONENEY. What say it I’ll all thy\n",
            "34815/34815 [==============================] - 154s 4ms/step - loss: 1.4994\n",
            "Epoch 7/10\n",
            "34810/34815 [============================>.] - ETA: 0s - loss: 1.4807\n",
            "----- Generating text after Epoch: 6\n",
            "----- Generating with seed: \"till I come again, No bed shall e’er be \"\n",
            "till I come again, No bed shall e’er be recomber drunkest of love-stormal With blood, and fit whost I warrant; and, I am gloins; Shall she were distail I mude such an it, and never have good keep.  OTHELLO. Mine swifthers, distolf.  FIUSTHES. My lord. Well you know this. The King antery it than over to hamper had of money     A coult hath see through upon musicule To us yives so proicke so that that tay, our right, Was that'st how in yo\n",
            "34815/34815 [==============================] - 151s 4ms/step - loss: 1.4807\n",
            "Epoch 8/10\n",
            "34808/34815 [============================>.] - ETA: 0s - loss: 1.4657\n",
            "----- Generating text after Epoch: 7\n",
            "----- Generating with seed: \"re none will sweat but for promotion,   \"\n",
            "re none will sweat but for promotion,       To feast moon Pare sose simfres is some fitoper,     Under my contition? His all, a’ name shall tay, now for my scrucled? His weaky spirow, do, and both all thou have. Do forth a desirance and maid-siles shall we given (The ladder in to grow hers tendens on Benwalks.  CYOBELLAN. O, I do saze the worm; ever warrary I am as steed, you one for this becolving to this camed banishment     To head n\n",
            "34815/34815 [==============================] - 151s 4ms/step - loss: 1.4657\n",
            "Epoch 9/10\n",
            "34808/34815 [============================>.] - ETA: 0s - loss: 1.4535\n",
            "----- Generating text after Epoch: 8\n",
            "----- Generating with seed: \"e, And to the most of praise add somethi\"\n",
            "e, And to the most of praise add something at myself. [Aside the DORTERBY OFFRASTES, her appolith, The French wit, vill hope of a mock perfect excellent where.   CLEOPATRA. And in her bonst the way?  PANTUCK. I was not the which give the partons of a general fledat Where yield we grantly pribralus           or surgun’d, by a monactions it the Glouce     For there ever gone.   BARIANE. Nay, tende hear: The worre is a showers of in twing \n",
            "34815/34815 [==============================] - 151s 4ms/step - loss: 1.4535\n",
            "Epoch 10/10\n",
            "34803/34815 [============================>.] - ETA: 0s - loss: 1.4428\n",
            "----- Generating text after Epoch: 9\n",
            "----- Generating with seed: \" with little water-drops.  'Why work'st \"\n",
            " with little water-drops.  'Why work'st heard, lies to Crach, I Pann, help my hall that a brought thy kins. Master no hour; here cheare, in the burial guilthars, Lords, Diess, loss, soldier in Palamonite.  BATDIANE. Why, slay thus more him, for mife, my refend and when you: way, if you we are thein none, and for my wars, beauthork,     Strike me with hellts her natus and we power.     When sheer in men, heit and from my Catter, Methy ga\n",
            "34815/34815 [==============================] - 151s 4ms/step - loss: 1.4428\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f84004679e8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "zE4a4O7Bp5x1"
      },
      "source": [
        "# Resources and Stretch Goals"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "uT3UV3gap9H6"
      },
      "source": [
        "## Stretch goals:\n",
        "- Refine the training and generation of text to be able to ask for different genres/styles of Shakespearean text (e.g. plays versus sonnets)\n",
        "- Train a classification model that takes text and returns which work of Shakespeare it is most likely to be from\n",
        "- Make it more performant! Many possible routes here - lean on Keras, optimize the code, and/or use more resources (AWS, etc.)\n",
        "- Revisit the news example from class, and improve it - use categories or tags to refine the model/generation, or train a news classifier\n",
        "- Run on bigger, better data\n",
        "\n",
        "## Resources:\n",
        "- [The Unreasonable Effectiveness of Recurrent Neural Networks](https://karpathy.github.io/2015/05/21/rnn-effectiveness/) - a seminal writeup demonstrating a simple but effective character-level NLP RNN\n",
        "- [Simple NumPy implementation of RNN](https://github.com/JY-Yoon/RNN-Implementation-using-NumPy/blob/master/RNN%20Implementation%20using%20NumPy.ipynb) - Python 3 version of the code from \"Unreasonable Effectiveness\"\n",
        "- [TensorFlow RNN Tutorial](https://github.com/tensorflow/models/tree/master/tutorials/rnn) - code for training a RNN on the Penn Tree Bank language dataset\n",
        "- [4 part tutorial on RNN](http://www.wildml.com/2015/09/recurrent-neural-networks-tutorial-part-1-introduction-to-rnns/) - relates RNN to the vanishing gradient problem, and provides example implementation\n",
        "- [RNN training tips and tricks](https://github.com/karpathy/char-rnn#tips-and-tricks) - some rules of thumb for parameterizing and training your RNN"
      ]
    }
  ]
}